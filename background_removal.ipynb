{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Background Removal with OpenCV\n",
        "\n",
        "This notebook demonstrates how to remove backgrounds from images using OpenCV's GrabCut algorithm.\n",
        "\n",
        "## Features\n",
        "- Batch processing of multiple images\n",
        "- Automatic background removal using GrabCut\n",
        "- Transparent PNG output\n",
        "- Progress tracking\n",
        "- Error handling and logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "logger = logging.getLogger(__name__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define input and output directories\n",
        "input_dir = Path(\"images\")\n",
        "output_dir = Path(\"output\")\n",
        "\n",
        "# Validate folder structure\n",
        "if not input_dir.exists():\n",
        "    logger.error(\"Input folder 'images/' not found.\")\n",
        "    raise FileNotFoundError(\"Missing input folder.\")\n",
        "    \n",
        "output_dir.mkdir(exist_ok=True)\n",
        "logger.info(f\"Output directory created: {output_dir}\")\n",
        "\n",
        "# Allowed image extensions\n",
        "valid_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_image(image_path, output_dir, margin=0.05):\n",
        "    \"\"\"\n",
        "    Process a single image to remove background using GrabCut algorithm.\n",
        "    \n",
        "    Args:\n",
        "        image_path (Path): Path to input image\n",
        "        output_dir (Path): Output directory\n",
        "        margin (float): Margin percentage for GrabCut rectangle\n",
        "    \n",
        "    Returns:\n",
        "        bool: Success status\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read image\n",
        "        img = cv2.imread(str(image_path))\n",
        "        if img is None:\n",
        "            logger.warning(f\"Skipping {image_path.name} (unable to read)\")\n",
        "            return False\n",
        "            \n",
        "        # Get image dimensions\n",
        "        height, width = img.shape[:2]\n",
        "        \n",
        "        # Calculate rectangle for GrabCut (with margin)\n",
        "        x = int(width * margin)\n",
        "        y = int(height * margin)\n",
        "        rect = (x, y, width - 2*x, height - 2*y)\n",
        "        \n",
        "        # Create mask and models for GrabCut\n",
        "        mask = np.zeros(img.shape[:2], np.uint8)\n",
        "        bgd_model = np.zeros((1, 65), np.float64)\n",
        "        fgd_model = np.zeros((1, 65), np.float64)\n",
        "        \n",
        "        # Apply GrabCut algorithm\n",
        "        cv2.grabCut(img, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
        "        \n",
        "        # Create binary mask\n",
        "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype(\"uint8\")\n",
        "        \n",
        "        # Convert to RGBA and apply mask to alpha channel\n",
        "        output_rgba = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
        "        output_rgba[:, :, 3] = mask2 * 255  # 0 for background, 255 for foreground\n",
        "        \n",
        "        # Save as PNG to preserve transparency\n",
        "        output_path = output_dir / image_path.with_suffix('.png').name\n",
        "        cv2.imwrite(str(output_path), output_rgba)\n",
        "        logger.info(f\"✓ Saved: {output_path.name}\")\n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"✗ Error processing {image_path.name}: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find all valid image files\n",
        "image_files = [f for f in input_dir.iterdir() if f.suffix.lower() in valid_extensions]\n",
        "\n",
        "if not image_files:\n",
        "    logger.warning(\"No valid image files found in 'images/' folder.\")\n",
        "    logger.info(f\"Please add images with extensions: {', '.join(valid_extensions)}\")\n",
        "else:\n",
        "    logger.info(f\"Found {len(image_files)} image(s) to process\")\n",
        "    \n",
        "    # Process all images with progress bar\n",
        "    successful = 0\n",
        "    for image_path in tqdm(image_files, desc=\"Processing images\", unit=\"image\"):\n",
        "        if process_image(image_path, output_dir):\n",
        "            successful += 1\n",
        "    \n",
        "    logger.info(f\"Processing complete! {successful}/{len(image_files)} images processed successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization\n",
        "\n",
        "Let's visualize the results by comparing original and processed images:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_results(original_path, processed_path, max_images=3):\n",
        "    \"\"\"\n",
        "    Display original and processed images side by side.\n",
        "    \"\"\"\n",
        "    processed_files = list(output_dir.glob(\"*.png\"))\n",
        "    \n",
        "    if not processed_files:\n",
        "        print(\"No processed images found.\")\n",
        "        return\n",
        "    \n",
        "    # Display up to max_images\n",
        "    for i, processed_file in enumerate(processed_files[:max_images]):\n",
        "        # Find corresponding original\n",
        "        original_file = input_dir / processed_file.name.replace('.png', '')\n",
        "        \n",
        "        # Try different extensions\n",
        "        for ext in valid_extensions:\n",
        "            potential_original = original_file.with_suffix(ext)\n",
        "            if potential_original.exists():\n",
        "                original_file = potential_original\n",
        "                break\n",
        "        \n",
        "        if original_file.exists():\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "            \n",
        "            # Original image\n",
        "            original_img = cv2.imread(str(original_file))\n",
        "            original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "            ax1.imshow(original_img)\n",
        "            ax1.set_title(f\"Original: {original_file.name}\")\n",
        "            ax1.axis('off')\n",
        "            \n",
        "            # Processed image\n",
        "            processed_img = cv2.imread(str(processed_file), cv2.IMREAD_UNCHANGED)\n",
        "            if processed_img.shape[2] == 4:  # RGBA\n",
        "                # Create white background for display\n",
        "                white_bg = np.ones((processed_img.shape[0], processed_img.shape[1], 3), dtype=np.uint8) * 255\n",
        "                alpha = processed_img[:, :, 3:4] / 255.0\n",
        "                rgb = processed_img[:, :, :3]\n",
        "                processed_img = (alpha * rgb + (1 - alpha) * white_bg).astype(np.uint8)\n",
        "            \n",
        "            ax2.imshow(processed_img)\n",
        "            ax2.set_title(f\"Processed: {processed_file.name}\")\n",
        "            ax2.axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(f\"Could not find original for {processed_file.name}\")\n",
        "\n",
        "# Display results if any images were processed\n",
        "if 'image_files' in locals() and image_files:\n",
        "    display_results(input_dir, output_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tips for Better Results\n",
        "\n",
        "1. **Image Quality**: Use high-quality images with clear contrast between subject and background\n",
        "2. **Subject Position**: Center your subject in the image for best results\n",
        "3. **Background Complexity**: Simple, uniform backgrounds work better than complex patterns\n",
        "4. **Lighting**: Well-lit subjects with distinct shadows work best\n",
        "5. **Margin Adjustment**: You can adjust the margin parameter (default 5%) if needed\n",
        "\n",
        "## Limitations\n",
        "\n",
        "- May struggle with complex backgrounds or subjects that blend into the background\n",
        "- No semantic understanding of objects\n",
        "- Best suited for images with clear foreground/background separation\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "For more advanced background removal, consider:\n",
        "- Deep learning models like U-2-Net, MODNet, or MediaPipe Selfie Segmentation\n",
        "- Manual refinement tools\n",
        "- Different segmentation algorithms\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
